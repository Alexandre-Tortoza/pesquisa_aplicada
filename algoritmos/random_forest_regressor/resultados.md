# AnÃ¡lise de Resultados Modelo Random Forest

## Significado das MÃ©tricas

| Sigla       | Nome Completo                   | DescriÃ§Ã£o                                                                                                                       |
| ----------- | ------------------------------- | ------------------------------------------------------------------------------------------------------------------------------- |
| **MAE**     | _Mean Absolute Error_           | Erro mÃ©dio absoluto â€” mede, em metros, o quanto as previsÃµes diferem dos valores reais. Valores menores indicam maior precisÃ£o. |
| **RMSE**    | _Root Mean Squared Error_       | Raiz do erro quadrÃ¡tico mÃ©dio â€” penaliza mais fortemente erros grandes. Ideal para avaliar estabilidade do modelo.              |
| **RÂ²**      | _Coeficiente de DeterminaÃ§Ã£o_   | Mede o quanto o modelo explica a variÃ¢ncia dos dados reais. Varia entre 0 e 1; quanto maior, melhor o ajuste.                   |
| **Holdout** | DivisÃ£o simples de treino/teste | Parte dos dados Ã© usada para treino e outra para teste, permitindo avaliaÃ§Ã£o direta da generalizaÃ§Ã£o.                           |
| **K-Fold**  | ValidaÃ§Ã£o Cruzada               | Divide os dados em _k_ partes (folds), treinando e testando vÃ¡rias vezes. Reduz viÃ©s e aumenta robustez da avaliaÃ§Ã£o.           |

---

## ConfiguraÃ§Ãµes Avaliadas

Foram testadas **cinco configuraÃ§Ãµes distintas** do algoritmo **Random Forest Regressor**, variando nÃºmero de Ã¡rvores, profundidade mÃ¡xima e tipo de validaÃ§Ã£o:

| Modelo    | EstratÃ©gia | Ãrvores | Profundidade MÃ¡x. | MAE Teste | RMSE Teste | RÂ² Teste | ObservaÃ§Ãµes                                             |
| --------- | ---------- | ------- | ----------------- | --------- | ---------- | -------- | ------------------------------------------------------- |
| **RF #1** | Holdout    | 100     | â€” (sem limite)    | 760.2     | 1298.6     | 0.62     | Modelo base (sem restriÃ§Ã£o de profundidade)             |
| **RF #2** | Holdout    | 200     | 30                | 749.7     | 1439.9     | 0.53     | Mais profundo, avalia overfitting e capacidade ampliada |
| **RF #3** | Holdout    | 300     | 15                | **857.9** | 1348.9     | 0.59     | Modelo robusto com grande diversidade de Ã¡rvores        |
| **RF #4** | K-Fold (5) | 50      | 10                | **974.8** | â€”          | **0.49** | Modelo leve, prioriza eficiÃªncia e generalizaÃ§Ã£o        |
| **RF #5** | K-Fold (5) | 150     | 12                | **931.0** | â€”          | **0.53** | ValidaÃ§Ã£o cruzada com regularizaÃ§Ã£o estrutural          |

---

## AnÃ¡lise dos Resultados

### ğŸŒ² RF #1 â€” Baseline (100 Ã¡rvores, sem limite de profundidade)

Este modelo serviu como **referÃªncia base** para comparaÃ§Ã£o.
Com RÂ² â‰ˆ **0.62** e MAE â‰ˆ **760 m**, apresentou **excelente desempenho inicial**, capturando relaÃ§Ãµes complexas entre as variÃ¡veis sem sinais fortes de sobreajuste.
A ausÃªncia de limitaÃ§Ã£o de profundidade permitiu melhor ajuste Ã s flutuaÃ§Ãµes do congestionamento, embora com risco moderado de overfitting.

> **Features mais importantes:** populaÃ§Ã£o total (37%), via expressa (15%), mÃªs (14%), hora do dia (13%).

---

### ğŸŒ³ RF #2 â€” Aumento de Profundidade (200 Ã¡rvores, max_depth=30)

Com maior nÃºmero de Ã¡rvores e profundidade ampliada, o modelo buscou **aprimorar a capacidade de aprendizado**.
O RÂ² caiu ligeiramente (0.53), sugerindo que **o aumento da complexidade trouxe overfitting**, refletido na discrepÃ¢ncia entre erros de treino e teste.
Ainda assim, o MAE permaneceu prÃ³ximo do baseline, mostrando **boa estabilidade do algoritmo**.

> **PopulaÃ§Ã£o total** continua como principal variÃ¡vel, reforÃ§ando sua influÃªncia no padrÃ£o de trÃ¡fego urbano.

---

### ğŸŒ² RF #3 â€” ConfiguraÃ§Ã£o Robusta (300 Ã¡rvores, max_depth=15)

Com mais Ã¡rvores, mas profundidade limitada, o modelo buscou **equilÃ­brio entre complexidade e generalizaÃ§Ã£o**.
Apresentou RÂ² = 0.59 e MAE â‰ˆ 858 m, com bom desempenho em estabilidade.
As importÃ¢ncias de features ficaram mais distribuÃ­das entre **populaÃ§Ã£o, via expressa e regiÃ£o**, demonstrando sensibilidade espacial do modelo.

> Essa configuraÃ§Ã£o Ã© **ideal para produÃ§Ã£o**, unindo desempenho consistente e menor variÃ¢ncia entre execuÃ§Ãµes.

---

### ğŸŒ¿ RF #4 â€” Modelo Leve (K-Fold, 50 Ã¡rvores, max_depth=10)

Voltado Ã  **eficiÃªncia computacional**, este modelo validado por 5 folds obteve RÂ² mÃ©dio de **0.49 Â± 0.002** e MAE â‰ˆ **975 m**.
Apesar de mais simples, manteve coerÃªncia de prediÃ§Ã£o e **baixa dispersÃ£o entre folds**, indicando **boa estabilidade estatÃ­stica**.
Ã‰ o mais indicado para cenÃ¡rios de teste rÃ¡pido ou baixa disponibilidade de hardware.

---

### ğŸŒ¾ RF #5 â€” RegularizaÃ§Ã£o Estrutural (K-Fold, 150 Ã¡rvores, max_depth=12)

A configuraÃ§Ã£o intermediÃ¡ria com validaÃ§Ã£o cruzada obteve **melhor desempenho mÃ©dio entre os K-Fold**, com RÂ² â‰ˆ **0.53 Â± 0.005** e MAE â‰ˆ **931 m**.
Mostra que **a regularizaÃ§Ã£o via limitaÃ§Ã£o de profundidade** e maior nÃºmero de Ã¡rvores resulta em **Ã³timo equilÃ­brio entre bias e variÃ¢ncia**.
Ã‰ o modelo mais robusto para validaÃ§Ãµes amplas.

> **Top 3 features:** PopulaÃ§Ã£o total (37%), via expressa (24%), regiÃ£o (22%).

---

## ConclusÃµes Gerais

- ğŸ† **Melhor modelo:** RF #1 (100 Ã¡rvores, sem limite de profundidade) â€” **RÂ² = 0.62, MAE = 760 m**.
  â†’ AlcanÃ§a excelente precisÃ£o e forte correlaÃ§Ã£o entre variÃ¡veis temporais e espaciais.

- âš™ï¸ Modelos com **K-Fold** apresentaram desempenho ligeiramente inferior, mas **maior estabilidade**, confirmando a robustez da abordagem.

- ğŸ§© **PopulaÃ§Ã£o total**, **via expressa** e **regiÃ£o** sÃ£o consistentemente as variÃ¡veis mais importantes em todas as configuraÃ§Ãµes.

- ğŸŒ Random Forest mantÃ©m desempenho superior ao KNN e comparÃ¡vel ao MLP, com **vantagem em interpretabilidade e estabilidade**.

---

## PrÃ³ximos Passos

1. ğŸ” Realizar _Grid Search_ para ajuste fino de `n_estimators`, `max_depth` e `min_samples_split`.
2. ğŸŒ³ Comparar resultados com **XGBoost**, que pode otimizar o uso de Ã¡rvores sequenciais.
3. ğŸ§  Avaliar combinaÃ§Ã£o de Random Forest com variÃ¡veis climÃ¡ticas e eventos.
4. ğŸ“Š Explorar mÃ©tricas adicionais como MAPE e erro percentual por faixa horÃ¡ria.

---

**Autor:** Alexandre Marques Tortoza Canoa
**Data:** Outubro de 2025
**Projeto:** _Pesquisa Aplicada â€” PrevisÃ£o de Congestionamentos em SÃ£o Paulo_
