# AnÃ¡lise de Resultados Modelo MLP (Redes Neurais)

## Significado das MÃ©tricas

| Sigla       | Nome Completo                   | DescriÃ§Ã£o                                                                                                                       |
| ----------- | ------------------------------- | ------------------------------------------------------------------------------------------------------------------------------- |
| **MAE**     | _Mean Absolute Error_           | Erro mÃ©dio absoluto â€” mede, em metros, o quanto as previsÃµes diferem dos valores reais. Valores menores indicam maior precisÃ£o. |
| **RMSE**    | _Root Mean Squared Error_       | Raiz do erro quadrÃ¡tico mÃ©dio â€” penaliza mais fortemente erros grandes. Ideal para avaliar estabilidade do modelo.              |
| **RÂ²**      | _Coeficiente de DeterminaÃ§Ã£o_   | Mede o quanto o modelo explica a variÃ¢ncia dos dados reais. Varia entre 0 e 1; quanto maior, melhor o ajuste.                   |
| **K-Fold**  | ValidaÃ§Ã£o Cruzada               | Divide os dados em _k_ partes (folds), treinando e testando vÃ¡rias vezes. Reduz viÃ©s e aumenta robustez da avaliaÃ§Ã£o.           |
| **Holdout** | DivisÃ£o simples de treino/teste | Parte dos dados Ã© usada para treino e outra para teste, permitindo avaliaÃ§Ã£o direta da generalizaÃ§Ã£o.                           |

---

## ConfiguraÃ§Ãµes Avaliadas

Foram testadas **cinco configuraÃ§Ãµes** da rede neural _Multi-Layer Perceptron (MLP)_ variando arquitetura, funÃ§Ã£o de ativaÃ§Ã£o, otimizador e estratÃ©gia de validaÃ§Ã£o:

| Modelo     | EstratÃ©gia | Arquitetura (camadas) | AtivaÃ§Ã£o | Otimizador | Learning Rate | Ã‰pocas | MAE Teste         | RMSE Teste | RÂ² Teste         |
| ---------- | ---------- | --------------------- | -------- | ---------- | ------------- | ------ | ----------------- | ---------- | ---------------- |
| **MLP #1** | Holdout    | (100, 50, 25)         | ReLU     | Adam       | 0.001         | 500    | 988.5             | 1531.6     | 0.47             |
| **MLP #2** | Holdout    | (256, 128, 64, 32)    | ReLU     | Adam       | 0.001         | 500    | **962.3**         | **1490.8** | **0.50**         |
| **MLP #3** | Holdout    | (64, 32)              | ReLU     | Adam       | 0.002         | 300    | 1005.1            | 1537.1     | 0.47             |
| **MLP #4** | K-Fold (5) | (100, 50)             | ReLU     | Adam       | 0.002         | 500    | **988.4 (mÃ©dia)** | â€”          | **0.47 (mÃ©dia)** |
| **MLP #5** | K-Fold (5) | (168, 64, 32)         | Tanh     | SGD        | 0.01          | 600    | 1502.7 (mÃ©dia)    | â€”          | 0.00             |

---

## AnÃ¡lise dos Resultados

### ğŸ”¹ MLP #1 â€” Baseline (3 camadas, ReLU, Adam)

Configurada como **arquitetura de referÃªncia**, a rede de trÃªs camadas intermediÃ¡rias apresentou desempenho sÃ³lido com RÂ² â‰ˆ 0.47.
O erro mÃ©dio de ~988 m mostra boa coerÃªncia com o KNN, sugerindo que o MLP captura parte relevante das relaÃ§Ãµes nÃ£o-lineares.
ConvergÃªncia alcanÃ§ada em 179 iteraÃ§Ãµes, indicando **treinamento estÃ¡vel e eficiente**.

---

### ğŸ”¹ MLP #2 â€” Rede Profunda (4 camadas, ReLU, Adam)

Essa arquitetura ampliada apresentou **melhor desempenho global**, com RÂ² â‰ˆ 0.50 e MAE â‰ˆ **962 m**.
O aumento de camadas e neurÃ´nios, aliado Ã  regularizaÃ§Ã£o L2, permitiu **melhor generalizaÃ§Ã£o** sem overfitting.
O resultado mostra que a rede neural consegue modelar interaÃ§Ãµes complexas entre variÃ¡veis temporais e regionais.
Ã‰ o **modelo mais promissor** entre os testados, equilibrando precisÃ£o e estabilidade.

---

### ğŸ”¹ MLP #3 â€” Arquitetura Compacta (2 camadas, ReLU, Adam)

VersÃ£o reduzida voltada Ã  **eficiÃªncia computacional** e inferÃªncia em tempo real.
Apesar da simplicidade, manteve desempenho semelhante ao baseline, com RÂ² = 0.47 e erro mÃ©dio de ~1 km.
Ideal para aplicaÃ§Ãµes prÃ¡ticas onde a latÃªncia Ã© fator crÃ­tico (ex.: sistemas embarcados).

---

### ğŸ”¹ MLP #4 â€” K-Fold ReLU (ValidaÃ§Ã£o Cruzada)

Avaliando robustez da arquitetura clÃ¡ssica (100, 50) via **validaÃ§Ã£o cruzada 5-fold**, o modelo apresentou **mÃ©dia RÂ² = 0.47 Â± 0.005**, com MAE â‰ˆ 988 m.
Os desvios baixos confirmam **consistÃªncia entre diferentes subconjuntos de dados**, validando a estabilidade da rede.

---

### ğŸ”¹ MLP #5 â€” Tanh + SGD (Experimento Alternativo)

Testando a combinaÃ§Ã£o **funÃ§Ã£o tanh + otimizador SGD**, o modelo nÃ£o convergiu adequadamente (RÂ² â‰ˆ 0.0, MAE > 1500 m).
A ativaÃ§Ã£o suave e o otimizador clÃ¡ssico exigiriam ajuste fino da taxa de aprendizado e momentum.
Resultado confirma que **Adam + ReLU** Ã© mais adequado ao problema, dadas as relaÃ§Ãµes nÃ£o lineares e heterogÃªneas do trÃ¢nsito urbano.

---

## ConclusÃµes Gerais

- ğŸ† **Melhor modelo:** MLP profunda com 4 camadas (256,128,64,32), ReLU e Adam â€” **RÂ² â‰ˆ 0.50, MAE â‰ˆ 960 m**.
  â†’ Excelente equilÃ­brio entre precisÃ£o e generalizaÃ§Ã£o.

- âš™ï¸ **ConfiguraÃ§Ãµes ReLU + Adam** apresentaram desempenho consistente, superando combinaÃ§Ãµes com SGD e tanh.

- ğŸ§© **VariÃ¡veis temporais e regionais** (hora, dia da semana, regiÃ£o) continuam sendo as mais influentes, reforÃ§ando achados de modelos anteriores (KNN, RF).

- ğŸ§  A capacidade de aprendizado nÃ£o-linear do MLP traz ganhos modestos sobre o KNN e Random Forest, mas mostra **potencial para evoluÃ§Ã£o com ajuste de hiperparÃ¢metros e features adicionais**.

---

## PrÃ³ximos Passos

1. ğŸ”§ Testar _learning rates_ adaptativos e dropout para reduzir variaÃ§Ãµes residuais.
2. ğŸ§® Comparar com **XGBoost** e **Random Forest** sob as mesmas mÃ©tricas.
3. ğŸŒ¦ï¸ Incorporar variÃ¡veis externas (clima, eventos, feriados) ao conjunto de treino.
4. âš¡ Explorar arquiteturas mais profundas (e.g., (512,256,128)) e normalizaÃ§Ã£o por batch.

---

**Autor:** Alexandre Marques Tortoza Canoa
**Data:** Outubro de 2025
**Projeto:** _Pesquisa Aplicada â€” PrevisÃ£o de Congestionamentos em SÃ£o Paulo_
