\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Análise Comparativa de Algoritmos de Aprendizado de Máquina na Predição do Crescimento do Trânsito Urbano a partir de Dados Populacionais\\
}

\author{\IEEEauthorblockN{Alexandre Marques Tortoza Canoa}
\IEEEauthorblockA{\textit{Escola Politécnica} \\
\textit{Pontifícia Universidade Católica do Paraná (PUCPR))}\\
Curitiba, PR, Brasil \\
a.marquestortoza@gmail.com}
}


\maketitle

\begin{abstract}
O agravamento do congestionamento urbano, impulsionado pelo crescimento populacional e pela expansão da frota de veículos, afeta diretamente a economia, o meio ambiente e o bem-estar social. Para estimar os níveis médios de tráfego nas regiões das cidades, foi aplicada uma abordagem preditiva que combina dados demográficos e históricos de trânsito. Após etapas de pré-processamento e codificação, foram testados diversos algoritmos de aprendizado supervisionado. Os modelos baseados em árvores apresentaram melhor desempenho, com destaque para o Random Forest. A população total foi a variável mais relevante, seguida por fatores temporais e espaciais. A integração entre dados populacionais e padrões de tráfego mostrou-se eficaz para apoiar o planejamento urbano e a gestão inteligente da mobilidade.
\end{abstract}

\begin{IEEEkeywords}
Predição de congestionamento, machine learning, dados populacionais, 
análise comparativa, random forest, tráfego urbano, série temporal, 
mobilidade urbana
\end{IEEEkeywords}

\section{Introdução}
O congestionamento urbano é um dos principais desafios enfrentados pelas grandes cidades contemporâneas. Intensificado pelo crescimento populacional acelerado e pela expansão desordenada da frota de veículos, esse fenômeno compromete diretamente a qualidade de vida, a eficiência econômica e a sustentabilidade ambiental \cite{1}. Estudos indicam que, em países desenvolvidos, os prejuízos causados pelo tráfego intenso somam bilhões de dólares por ano, refletindo em tempo perdido, aumento do consumo de combustível, elevação dos níveis de poluição e maior incidência de acidentes de trânsito. Na América Latina, o cenário é agravado pelo crescimento urbano desordenado e pela rápida motorização.

\subsection{Motivação}
Mitigar os impactos econômicos, sociais e ambientais do congestionamento é uma prioridade nas grandes metrópoles. A poluição, os atrasos nas viagens e os custos elevados de transporte exigem soluções eficazes e escaláveis. Antecipar cenários críticos de tráfego é essencial para otimizar a mobilidade e apoiar decisões em tempo real. Algoritmos de aprendizado de máquina desempenham papel significativo na análise de tráfego, permitindo identificar padrões complexos e prever situações de congestionamento \cite{2}. Quando aplicadas a dados históricos, essas técnicas viabilizam ações preventivas como ajustes semafóricos, orientação aos motoristas e melhorias no transporte público. Diversas abordagens têm demonstrado o potencial dessas técnicas para aumentar a eficiência do sistema viário.

\subsection{Problema}
Nas áreas urbanas, especialmente em grandes centros, o crescimento populacional e a motorização acelerada intensificam os congestionamentos, gerando impactos diretos na população e na economia. Entre os principais efeitos estão o aumento da poluição atmosférica e sonora, o maior consumo de combustível, a perda de tempo nas viagens e o crescimento das taxas de acidentes e infrações. Nos Estados Unidos, o congestionamento é apontado como uma ameaça ao desempenho econômico, enquanto na América Latina o problema se agrava com o crescimento desordenado das cidades.

\subsection{Objetivo}
Esta pesquisa busca prever, com antecedência, o nível de congestionamento em vias urbanas da cidade de São Paulo, utilizando séries temporais de volume de veículos. O objetivo é modelar a variação do fluxo ao longo do tempo, identificar padrões recorrentes e antecipar os momentos e locais mais propensos a congestionamentos, oferecendo suporte ao planejamento e à gestão inteligente do trânsito.

\subsection{Artefato}
Será desenvolvido um sistema de aprendizado de máquina treinado com dados históricos de tráfego e rótulos de congestionamento. Após o treinamento, o modelo receberá dados atuais como entrada e estimará o nível de congestionamento de curto prazo, disponibilizando as previsões em uma interface voltada ao monitoramento e à tomada de decisão antecipada.

\section{Estado da Arte}
O congestionamento urbano permanece como um dos desafios mais persistentes das grandes metrópoles contemporâneas, intensificado pelo crescimento populacional acelerado e pela expansão desordenada das áreas urbanas. Em São Paulo, esse fenômeno atinge dimensões críticas, com a cidade frequentemente figurando entre as mais congestionadas do mundo e registrando perdas econômicas estimadas em bilhões de reais anualmente \cite{3}.

Tradicionalmente, as abordagens para mitigação do congestionamento concentravam-se em soluções infraestruturais de larga escala, como a ampliação da malha viária, estratégias predominantes nas décadas de 1950 e 1960 sob a influência do modelo rodoviarista \cite{1}. Contudo, a constatação de que a ampliação da oferta viária frequentemente induz à demanda adicional por deslocamentos motorizados levou à necessidade de repensar essas abordagens.

A partir dos anos 1990, o debate passou a incorporar dimensões sociais e de equidade urbana. Pereira e Schwanen \cite{4} demonstraram que trabalhadores de baixa renda, residentes em regiões periféricas, gastam até 20\% mais tempo em deslocamentos diários quando comparados a indivíduos de maior poder aquisitivo. Essa desigualdade espacial evidencia a necessidade de compreender não apenas os padrões gerais de tráfego, mas também sua relação com características demográficas e distribuição populacional.

O congestionamento resulta de uma combinação complexa de fatores recorrentes e não recorrentes. Entre os fatores recorrentes, destacam-se o volume excessivo de veículos, a capacidade limitada das vias e os horários de pico. Já os fatores não recorrentes incluem incidentes, obras e condições climáticas adversas \cite{2}. Essa multiplicidade de causas demanda ferramentas analíticas sofisticadas, capazes de processar grandes volumes de dados heterogêneos e identificar padrões complexos.

Com o advento das tecnologias digitais e a consolidação da era do Big Data, novas perspectivas metodológicas emergiram. A disponibilidade crescente de dados georreferenciados, séries temporais de tráfego e informações demográficas detalhadas viabilizou a aplicação de técnicas de aprendizado de máquina para previsão de condições de tráfego. Diferentemente das abordagens baseadas em modelos físicos e simulações de engenharia, que demandam parametrizações complexas, os modelos orientados por dados têm demonstrado capacidade superior de generalização e adaptação a padrões emergentes \cite{5}.

Estudos recentes têm explorado diferentes arquiteturas de aprendizado de máquina aplicadas à previsão de congestionamentos, demonstrando que modelos baseados em ensemble learning, como Random Forest e Gradient Boosting, superam técnicas lineares tradicionais em termos de precisão preditiva, especialmente quando confrontados com padrões não lineares \cite{6}. A capacidade desses modelos de capturar relações hierárquicas torna-os particularmente adequados para contextos urbanos caracterizados por heterogeneidade espacial e temporal.

A regressão linear, apesar de sua simplicidade, permanece relevante como baseline metodológico. Algoritmos baseados em instâncias, como K-Nearest Neighbors, têm sido aplicados devido à sua capacidade de capturar padrões locais, embora apresentem limitações de custo computacional em datasets volumosos. As técnicas de ensemble learning, representadas por Random Forest e XGBoost, têm alcançado desempenho superior em diversos problemas de previsão de tráfego, apresentando robustez contra overfitting e eficiência computacional em datasets de grande escala.

As redes neurais artificiais, em especial os Multilayer Perceptrons, constituem outra classe relevante de modelos. Embora exijam maiores volumes de dados para treinamento e apresentem menor interpretabilidade, oferecem flexibilidade arquitetural que permite modelar interações de alta ordem entre variáveis.

Um aspecto crítico na aplicação de técnicas de aprendizado de máquina é a capacidade de explicar as predições geradas. Técnicas de interpretabilidade como SHAP têm sido crescentemente adotadas para quantificar a contribuição individual de cada variável nas previsões de modelos complexos, permitindo que gestores urbanos compreendam quais fatores exercem maior influência sobre os padrões de congestionamento \cite{7}. Essa transparência metodológica é fundamental para a validação científica dos modelos e para a construção de confiança nas ferramentas computacionais.

A relação entre características populacionais e padrões de congestionamento constitui uma linha de investigação particularmente relevante, mas ainda pouco explorada. Enquanto estudos tradicionais concentram-se em variáveis diretas de tráfego, a incorporação de dados demográficos desagregados por região, faixa etária e gênero pode revelar padrões estruturais subjacentes que refletem a organização espacial das atividades urbanas.

No contexto específico de São Paulo, a heterogeneidade demográfica entre os diferentes distritos, combinada com a desigual distribuição de empregos formais e infraestrutura de transporte, sugere que modelos preditivos podem beneficiar-se significativamente da incorporação de variáveis populacionais. A modelagem conjunta dessas características demográficas com séries históricas de congestionamento permite não apenas prever condições futuras de tráfego, mas também identificar áreas prioritárias para intervenções de planejamento urbano.

Diante desse panorama, a presente pesquisa explora especificamente a capacidade de diferentes técnicas de aprendizado de máquina em prever padrões de congestionamento a partir de características populacionais desagregadas por distrito, sexo e faixa etária. A proposta metodológica enfatiza não apenas a comparação de desempenho preditivo entre os modelos, mas também a análise de interpretabilidade por meio de técnicas como SHAP, visando identificar quais variáveis demográficas exercem maior influência nos padrões de congestionamento observados na cidade de São Paulo.

\section{Metodologia}
A metodologia adotada nesta pesquisa foi estruturada em quatro etapas principais, coleta de dados, tratamento e preparação, testes com algoritmos de machine learning e análise dos resultados. O pipeline seguido está ilustrado na Figura 1.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.4\textwidth]{pipeline.png}
\caption{Pipeline da metodologia}
\label{fig:pipeline}
\end{figure}

Inicialmente, partimos de um dataset referente ao trânsito da cidade de São Paulo. Para enriquecer a análise e estabelecer uma correlação entre o comportamento do trânsito e o crescimento populacional da capital, buscamos dados complementares no portal https://dadosabertos.sp.gov.br. De lá, extraímos um segundo dataset contendo informações sobre a população de São Paulo ao longo dos anos.

Na segunda etapa, realizamos a limpeza e padronização dos dados. Os datasets apresentavam ruídos, campos fora de padrão e diferentes codificações de texto (encodings), o que exigiu um processo cuidadoso de tratamento para garantir a compatibilidade e integridade das informações. Após a unificação dos dados, com as variáveis devidamente estruturadas, avançamos para a etapa de testes com algoritmos de aprendizado de máquina.

Os testes foram conduzidos com diferentes modelos, e os resultados foram armazenados para posterior comparação, tanto em termos de desempenho quanto de qualidade preditiva. Essa abordagem permitiu avaliar a eficácia dos algoritmos frente aos dados tratados e entender melhor a relação entre o crescimento populacional e o impacto no trânsito da cidade.

\subsection{Datasets}
O ponto de partida da pesquisa foi a seleção de um dataset sobre o trânsito da cidade de São Paulo. Este conjunto de dados se mostrou especialmente relevante por conter informações como dia, hora, região e, principalmente, o nível de congestionamento, variável central para os objetivos do estudo. Algumas colunas adicionais estavam presentes, mas foram descartadas por não contribuírem diretamente para a análise proposta.

Para estabelecer uma correlação entre o comportamento do trânsito e o crescimento populacional da cidade, foi incorporado um segundo dataset, obtido por meio do portal dadosabertos.gov.sp Este conjunto trazia dados populacionais da capital paulista ao longo dos anos, incluindo as variáveis ano, distrito, sexo, faixa etária e população total.

Apesar da riqueza informacional, esse segundo dataset apresentou desafios técnicos. Havia ruídos nos dados, campos fora de padrão e codificações de texto distintas (encodings), o que exigiu um esforço adicional para uniformização e tratamento adequado. Um ponto específico que merece destaque é a estrutura da variável idade, que estava agrupada em faixas etárias (por exemplo, "10 a 14 anos", "15 a 19 anos"). Essa segmentação dificultou a filtragem precisa de indivíduos com idade mínima para conduzir veículos (a partir dos 18 anos), sendo possível apenas considerar faixas a partir dos 20 anos, o que introduz um pequeno desvio na análise.

A aquisição dos dados, portanto, envolveu não apenas a seleção criteriosa dos conjuntos mais relevantes, mas também a antecipação dos desafios que seriam enfrentados nas etapas seguintes de tratamento e modelagem.

\subsection{limpeza e preparacao}

Para assegurar a consistência e a qualidade dos dados utilizados na modelagem preditiva, foram desenvolvidos dois pipelines automatizados de pré-processamento, um voltado ao tratamento dos dados populacionais e outro dedicado ao conjunto de dados de congestionamentos de tráfego. Ambos os processos tiveram como objetivo padronizar formatos, remover inconsistências e preparar os dados para a etapa de integração e posterior aplicação de algoritmos de aprendizado de máquina.

O conjunto populacional passou por um tratamento mais detalhado, executado pelo script python . Inicialmente, todos os campos textuais foram normalizados por meio da remoção de acentuação e da padronização de espaços, garantindo uniformidade entre distritos e categorias. Em seguida, foi aplicado um filtro para manter apenas as faixas etárias com idade igual ou superior a 20 anos, de por conta de limitações do dataset, mais diretamente relacionada aos padrões de deslocamento urbano. Na sequência, foi criada uma nova variável denominada região, obtida a partir do mapeamento de cada distrito para uma das cinco grandes áreas geográficas de São Paulo: norte, sul, leste, oeste e centro. Esse mapeamento foi implementado por meio de um dicionário abrangendo os 96 distritos oficiais do município, permitindo uma agregação coerente com as divisões espaciais utilizadas nos dados de tráfego. Por fim, distritos que não possuíam correspondência foram identificados e registrados em um arquivo auxiliar para verificação manual, garantindo a completude do mapeamento antes da exportação final dos dados, que foram salvos em formato CSV com codificação UTF-8 padronizada.

O conjunto de dados de tráfego, processado pelo script python, exigiu um tratamento voltado principalmente à validação e à consistência das informações temporais e geográficas. As etapas iniciais incluíram a normalização dos campos textuais referentes a vias, regiões e expressways, removendo acentuação e espaços redundantes. Em seguida, foi realizada a validação das variáveis de data e hora, assegurando que apenas registros com formato temporal correto fossem mantidos. O campo de tamanho do congestionamento também passou por verificação, sendo eliminados valores negativos, nulos ou não numéricos. As regiões foram padronizadas para um formato em letras minúsculas e comparadas a uma lista de referência contendo as mesmas categorias usadas no dataset populacional, garantindo a compatibilidade entre as bases. Registros duplicados foram identificados e removidos, e, ao final, foi gerado um relatório estatístico que resumiu a distribuição dos congestionamentos por região, além de medidas descritivas como média, mediana e desvio padrão do tamanho dos congestionamentos.

Ambos os conjuntos de dados resultantes foram padronizados quanto à codificação e ao delimitador, de forma a assegurar compatibilidade durante o processo de integração. Essa padronização foi fundamental para que os datasets pudessem ser combinados por meio das variáveis região e ano, possibilitando análises conjuntas sobre o impacto da densidade populacional no comportamento do tráfego e permitindo que as etapas seguintes de modelagem preditiva fossem conduzidas de maneira consistente e reprodutível.


\begin{thebibliography}{00}

\bibitem{1} G. S. B. Vianna and C. Young, ``Em busca do tempo perdido: uma estimativa do produto perdido em trânsito no Brasil,'' \textit{Revista de Economia Contemporânea}, vol. 19, no. 3, pp. 403--416, set.--dez. 2015.
\bibitem{2} M. Akhtar and S. Moridpour, ``A review of traffic congestion prediction using artificial intelligence,'' \textit{Journal of Advanced Transportation}, vol. 2021, pp. 1--18, 2021.
\bibitem{3} D. B. Vale, ``The welfare costs of traffic congestion in São Paulo Metropolitan Area,'' Tese (Doutorado), Universidade de São Paulo, São Paulo, 2018.
\bibitem{4} R. H. M. Pereira and T. Schwanen, ``Tempo de deslocamento casa-trabalho no Brasil (1992-2009): diferenças entre regiões metropolitanas, níveis de renda e sexo,'' Texto para Discussão, IPEA, Brasília, n. 1813, 2013.
\bibitem{5} E. I. Vlahogianni, M. G. Karlaftis, and J. C. Golias, ``Short-term traffic forecasting: where we are and where we're going,'' \textit{Transportation Research Part C: Emerging Technologies}, vol. 43, pp. 3--19, 2014.
\bibitem{6} P. Zechin et al., ``Traffic congestion prediction using machine learning techniques,'' in \textit{Proceedings of the 11th Brazilian Conference on Intelligent Systems}, Campinas: SBC, 2022, pp. 214--225.
\bibitem{7} S. M. Lundberg and S.-I. Lee, ``A unified approach to interpreting model predictions,'' in \textit{Proceedings of the 31st Conference on Neural Information Processing Systems}, Long Beach: NIPS, 2017, pp. 4765--4774.

\end{thebibliography}


\end{document}
